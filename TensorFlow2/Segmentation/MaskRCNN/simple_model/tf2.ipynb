{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "os.environ['TF_XLA_FLAGS'] = \"--tf_xla_auto_jit=fusible\"\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "import horovod.tensorflow as hvd\n",
    "hvd.init()\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[hvd.rank()], True)\n",
    "tf.config.set_visible_devices(physical_devices[hvd.rank()], 'GPU')\n",
    "devices = tf.config.list_logical_devices('GPU')\n",
    "\n",
    "tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n",
    "#policy = mixed_precision.Policy('mixed_float16')\n",
    "#mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from statistics import mean\n",
    "import GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mask_rcnn.tf2_model import MaskRCNN\n",
    "from mask_rcnn.hyperparameters import dataset_params\n",
    "from mask_rcnn.hyperparameters import mask_rcnn_params\n",
    "from mask_rcnn import dataset_utils\n",
    "from mask_rcnn.training import losses, learning_rates\n",
    "from simple_model.tf2 import weight_loader, train, scheduler\n",
    "from simple_model import model_v2\n",
    "\n",
    "train_file_pattern = '/home/ubuntu/data/coco/tf_record/train*'\n",
    "eval_file_pattern = '/home/ubuntu/data/coco/tf_record/val*'\n",
    "batch_size = 4\n",
    "global_batch_size = batch_size * hvd.size()\n",
    "images = 118287\n",
    "steps_per_epoch = images//global_batch_size\n",
    "train_data_params = dataset_params.get_data_params()\n",
    "eval_data_params = dataset_params.get_data_params()\n",
    "params = mask_rcnn_params.default_config().values()\n",
    "train_data_params['batch_size'] = batch_size\n",
    "eval_data_params['batch_size'] = 1\n",
    "params['finetune_bn'] = False\n",
    "params['train_batch_size'] = batch_size\n",
    "params['l2_weight_decay'] = 1e-4\n",
    "params['init_learning_rate'] = 2e-3 * global_batch_size\n",
    "params['warmup_learning_rate'] = 2e-4 * global_batch_size\n",
    "params['warmup_steps'] = 4096//global_batch_size\n",
    "params['learning_rate_steps'] = [steps_per_epoch * 9, steps_per_epoch * 11]\n",
    "params['learning_rate_levels'] = [2e-4 * global_batch_size, 2e-5 * global_batch_size]\n",
    "params['momentum'] = 0.9\n",
    "params['use_batched_nms'] = False\n",
    "params['use_custom_box_proposals_op'] = True\n",
    "params['amp'] = True\n",
    "params['include_groundtruth_in_features'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MaskRCNN] INFO    : Using Dataset Sharding with Horovod\n"
     ]
    }
   ],
   "source": [
    "train_loader = dataset_utils.FastDataLoader(train_file_pattern, train_data_params)\n",
    "train_tdf = train_loader(train_data_params)\n",
    "train_tdf = train_tdf.apply(tf.data.experimental.prefetch_to_device(devices[0].name, \n",
    "                                                                    buffer_size=tf.data.experimental.AUTOTUNE))\n",
    "train_iter = iter(train_tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MaskRCNN] INFO    : Using Dataset Sharding with Horovod\n"
     ]
    }
   ],
   "source": [
    "eval_loader = dataset_utils.FastDataLoader(eval_file_pattern, eval_data_params)\n",
    "eval_tdf = eval_loader(eval_data_params)\n",
    "eval_tdf = eval_tdf.apply(tf.data.experimental.prefetch_to_device(devices[0].name, \n",
    "                                                                    buffer_size=tf.data.experimental.AUTOTUNE))\n",
    "eval_iter = iter(eval_tdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_rcnn = model_v2.MRCNN(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = next(train_iter)\n",
    "model_outputs = mask_rcnn(features, labels, params, is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_loader.load_resnet_checkpoint(mask_rcnn, '../resnet/resnet-nhwc-2018-02-07/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=8.003389>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.train_forward(features, labels, params, mask_rcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(params['learning_rate_steps'],\n",
    "                                                                [params['init_learning_rate']] \\\n",
    "                                                                + params['learning_rate_levels'])\n",
    "schedule = scheduler.WarmupScheduler(schedule, params['warmup_learning_rate'],\n",
    "                                     params['warmup_steps'])\n",
    "optimizer = tf.keras.optimizers.SGD(schedule, momentum=0.9)\n",
    "optimizer = tf.keras.mixed_precision.experimental.LossScaleOptimizer(optimizer, 'dynamic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(features, labels, params, model, opt, first=False):\n",
    "    with tf.GradientTape() as tape:\n",
    "        total_loss = train.train_forward(features, labels, params, model)\n",
    "        scaled_loss = optimizer.get_scaled_loss(total_loss)\n",
    "    tape = hvd.DistributedGradientTape(tape)\n",
    "    scaled_gradients = tape.gradient(scaled_loss, model.trainable_variables)\n",
    "    gradients = optimizer.get_unscaled_gradients(scaled_gradients)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    if first:\n",
    "        hvd.broadcast_variables(model.variables, 0)\n",
    "        hvd.broadcast_variables(opt.variables(), root_rank=0)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = train_step(features, labels, params, mask_rcnn, optimizer, first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6630, LR: 0.0080:  72%|███████▏  | 10647/14785 [37:37<14:26,  4.78it/s] "
     ]
    }
   ],
   "source": [
    "if hvd.rank()==0:\n",
    "    p_bar = tqdm(range(steps_per_epoch//2))\n",
    "    loss_history = []\n",
    "else:\n",
    "    p_bar = range(steps_per_epoch//2)\n",
    "for i in p_bar:\n",
    "    features, labels = next(train_iter)\n",
    "    total_loss = train_step(features, labels, params, mask_rcnn, optimizer)\n",
    "    if hvd.rank()==0:\n",
    "        loss_history.append(total_loss.numpy())\n",
    "        smoothed_loss = mean(loss_history[-50:])\n",
    "        p_bar.set_description(\"Loss: {0:.4f}, LR: {1:.4f}\".format(smoothed_loss, \n",
    "                                                                  schedule(optimizer.iterations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def pred(features, params):\n",
    "    out = mask_rcnn(features, None, params, is_training=False)\n",
    "    out['image_info'] = features['image_info']\n",
    "    out['source_id'] = features['source_ids']\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_mem = GPUtil.getGPUs()[0].memoryUsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15664.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mem 9420.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [03:50<00:00, 21.70it/s]\n"
     ]
    }
   ],
   "source": [
    "some_predictions = []\n",
    "for i in tqdm(range(5000)):\n",
    "    eval_features, eval_labels = next(eval_iter)\n",
    "    some_predictions.append(pred(eval_features, params))\n",
    "    #gpu_mem = GPUtil.getGPUs()[0].memoryUsed\n",
    "    '''if gpu_mem>12000:\n",
    "        print(\"stopping at iteration {}\".format(i))\n",
    "        break'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([178744])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_features['source_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[270402, 458255,  61171, 469828]\n",
    "#[110638]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_latest_p37)",
   "language": "python",
   "name": "conda_tensorflow2_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
